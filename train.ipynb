{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:27.909451Z",
     "start_time": "2022-04-07T13:52:27.905296Z"
    },
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-06-13T12:19:33.091090Z",
     "iopub.status.busy": "2021-06-13T12:19:33.090718Z",
     "iopub.status.idle": "2021-06-13T12:19:33.100126Z",
     "shell.execute_reply": "2021-06-13T12:19:33.098770Z",
     "shell.execute_reply.started": "2021-06-13T12:19:33.091058Z"
    }
   },
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from __future__ import division\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import random\n",
    "import pandas as pd\n",
    "import os, fnmatch, copy, time\n",
    "import numpy as np\n",
    "import math\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, models\n",
    "from torchvision import transforms as T\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from datetime import datetime\n",
    "from PIL import Image\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:28.194199Z",
     "start_time": "2022-04-07T13:52:28.183774Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:19:33.103118Z",
     "iopub.status.busy": "2021-06-13T12:19:33.102419Z",
     "iopub.status.idle": "2021-06-13T12:19:33.123378Z",
     "shell.execute_reply": "2021-06-13T12:19:33.122097Z",
     "shell.execute_reply.started": "2021-06-13T12:19:33.103060Z"
    }
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms as T\n",
    "from torch.utils import data\n",
    "\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"  # Arrange GPU devices starting from 0\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]= \"1\"  # Set the GPU 1 to use\n",
    "random.seed(1)\n",
    "\n",
    "def get_filepath(dir_root):\n",
    "    file_paths = []\n",
    "    for root, dirs, files in os.walk(dir_root):\n",
    "        for file in files:\n",
    "            file_paths.append(os.path.join(root, file))\n",
    "    return file_paths\n",
    "\n",
    "class DriverDatasetTrain(data.Dataset):\n",
    "    def __init__(self, data_root, transforms=None, train=True):\n",
    "        self.train = train\n",
    "        imgs_in = get_filepath(data_root)\n",
    "        random.shuffle(imgs_in)\n",
    "        imgs_num = len(imgs_in)\n",
    "\n",
    "        if transforms is None:\n",
    "            self.transforms = T.Compose([\n",
    "                                         T.Resize(size = (224, 224)),\n",
    "                                         T.ToTensor(),\n",
    "                                         T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                         ])\n",
    "\n",
    "        if self.train:\n",
    "            self.imgs = imgs_in[:int(0.7 * imgs_num)]\n",
    "        else:\n",
    "            self.imgs = imgs_in[int(0.7 * imgs_num):]\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs[index]\n",
    "\n",
    "        label = int(img_path.split('/')[-2][1:])\n",
    "        data = Image.open(img_path)\n",
    "        data = self.transforms(data)\n",
    "        return data, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "\n",
    "class DriverDatasetTest(data.Dataset):\n",
    "    def __init__(self, data_root, transforms=None):\n",
    "\n",
    "        self.imgs_in = get_filepath(data_root)\n",
    "\n",
    "        if transforms is None:\n",
    "            self.transforms = T.Compose([T.Resize(size=(224,224)),\n",
    "                                         T.ToTensor(),\n",
    "                                         T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                                         ])\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.imgs_in[index]\n",
    "\n",
    "        data = Image.open(img_path)\n",
    "        data = self.transforms(data)\n",
    "        return data, img_path\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.imgs_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:28.348762Z",
     "start_time": "2022-04-07T13:52:28.344305Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:19:33.128714Z",
     "iopub.status.busy": "2021-06-13T12:19:33.128376Z",
     "iopub.status.idle": "2021-06-13T12:19:33.140628Z",
     "shell.execute_reply": "2021-06-13T12:19:33.139238Z",
     "shell.execute_reply.started": "2021-06-13T12:19:33.128683Z"
    }
   },
   "outputs": [],
   "source": [
    "def train(model, device, train_loader, optimizer, epoch, train_losses):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = torch.nn.CrossEntropyLoss()(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % 50 ==0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()))\n",
    "        \n",
    "    train_losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:28.494770Z",
     "start_time": "2022-04-07T13:52:28.490029Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:19:33.145633Z",
     "iopub.status.busy": "2021-06-13T12:19:33.145208Z",
     "iopub.status.idle": "2021-06-13T12:19:33.158089Z",
     "shell.execute_reply": "2021-06-13T12:19:33.156684Z",
     "shell.execute_reply.started": "2021-06-13T12:19:33.145559Z"
    }
   },
   "outputs": [],
   "source": [
    "def validation(model, device, vali_loader, vali_losses):\n",
    "    model.eval()\n",
    "    vali_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in vali_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            vali_loss += F.cross_entropy(output, target, reduction = 'sum').item()\n",
    "            pred = output.argmax(dim = 1, keepdim = True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "    vali_loss/=len(vali_loader.dataset)\n",
    "    print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        vali_loss, correct, len(vali_loader.dataset), 100. * correct / len(vali_loader.dataset)))\n",
    "    \n",
    "    vali_losses.append(vali_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:28.627578Z",
     "start_time": "2022-04-07T13:52:28.625120Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:19:33.160684Z",
     "iopub.status.busy": "2021-06-13T12:19:33.160068Z",
     "iopub.status.idle": "2021-06-13T12:19:33.170099Z",
     "shell.execute_reply": "2021-06-13T12:19:33.168929Z",
     "shell.execute_reply.started": "2021-06-13T12:19:33.160632Z"
    }
   },
   "outputs": [],
   "source": [
    "def set_parameter_requires_grad(model, feature_extracting):\n",
    "    if feature_extracting:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:28.766537Z",
     "start_time": "2022-04-07T13:52:28.757628Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:19:33.344177Z",
     "iopub.status.busy": "2021-06-13T12:19:33.343748Z",
     "iopub.status.idle": "2021-06-13T12:19:33.358963Z",
     "shell.execute_reply": "2021-06-13T12:19:33.357561Z",
     "shell.execute_reply.started": "2021-06-13T12:19:33.344130Z"
    }
   },
   "outputs": [],
   "source": [
    "model_name = \"\"\n",
    "num_classes=11\n",
    "feature_extract=True\n",
    "use_pretrained=False #False\n",
    "def initialize_model(model_name, num_classes=11, feature_extract=True, use_pretrained=False):\n",
    "    # Initialize these variables which will be set in this if statement. Each of these\n",
    "    #   variables is model specific.\n",
    "    model_ft = None\n",
    "    input_size = 0\n",
    "    \n",
    "    if model_name == \"resnet50\":\n",
    "        \"\"\" Resnet50\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet50(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnet152\":\n",
    "        \"\"\" Resnet152\n",
    "        \"\"\"\n",
    "        model_ft = models.resnet152(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"resnext101_32x8d\":\n",
    "        \"\"\" Resnext101_32x8d\n",
    "        \"\"\"\n",
    "        model_ft = models.resnext101_32x8d(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"wide_resnet101_2\":\n",
    "        \"\"\" Wide_resnet101_2\n",
    "        \"\"\"\n",
    "        model_ft = models.wide_resnet101_2(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.fc.in_features\n",
    "        model_ft.fc = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "        \n",
    "    elif model_name == \"densenet\":\n",
    "        \"\"\" Densenet161\n",
    "        \"\"\"\n",
    "        model_ft = models.densenet161()\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        num_ftrs = model_ft.classifier.in_features\n",
    "        model_ft.classifier = nn.Linear(num_ftrs, num_classes)\n",
    "        input_size = 224\n",
    "    \n",
    "    elif model_name == \"squeezenet\":\n",
    "        \"\"\" Squeezenet1_1\n",
    "        \"\"\"\n",
    "        model_ft = models.squeezenet1_1(pretrained=use_pretrained)\n",
    "        set_parameter_requires_grad(model_ft, feature_extract)\n",
    "        model_ft.classifier[1] = nn.Conv2d(512, num_classes, kernel_size=(1,1), stride=(1,1))\n",
    "        model_ft.num_classes = num_classes\n",
    "        input_size = 224\n",
    "        \n",
    "    else:\n",
    "        print(\"Invalid model name, exiting...\")\n",
    "        exit()\n",
    "    \n",
    "    return model_ft, input_size\n",
    "    \n",
    "# Initialize the model for this run\n",
    "# model_ft, input_size = initialize_model(model_name, num_classes, feature_extract, use_pretrained=False)\n",
    "\n",
    "# Print the model we just instantiated\n",
    "# print(model_ft)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:28.891531Z",
     "start_time": "2022-04-07T13:52:28.889272Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:19:33.362603Z",
     "iopub.status.busy": "2021-06-13T12:19:33.361716Z",
     "iopub.status.idle": "2021-06-13T12:19:33.377396Z",
     "shell.execute_reply": "2021-06-13T12:19:33.376303Z",
     "shell.execute_reply.started": "2021-06-13T12:19:33.362552Z"
    }
   },
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "max_epoch = 100 #max_epoch             200\n",
    "alpha = 0.001 #learning rate           0.001 0.005 0.01 0.05 0.1\n",
    "bth_size = 64 #batch size             32 64 128 256 512 1024\n",
    "gam = 0.95 #gamma(discount factor)    0.1 0.5 0.9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:29.534204Z",
     "start_time": "2022-04-07T13:52:29.380966Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:19:33.383198Z",
     "iopub.status.busy": "2021-06-13T12:19:33.382768Z",
     "iopub.status.idle": "2021-06-13T12:23:53.495745Z",
     "shell.execute_reply": "2021-06-13T12:23:53.494583Z",
     "shell.execute_reply.started": "2021-06-13T12:19:33.383150Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_path = './imgs/train'\n",
    "test_data_path = './imgs/test2'\n",
    "\n",
    "train_data = DriverDatasetTrain(train_data_path, train=True)\n",
    "train_loader = DataLoader(dataset=train_data, shuffle=True, batch_size=bth_size, num_workers=4)\n",
    "\n",
    "vali_data = DriverDatasetTrain(train_data_path, train=False)\n",
    "vali_loader = DataLoader(dataset=vali_data, shuffle=False, batch_size=bth_size, num_workers=4)\n",
    "\n",
    "test_data = DriverDatasetTest(test_data_path)\n",
    "test_loader = DataLoader(dataset = test_data, shuffle=False, batch_size=1, num_workers=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-06T15:40:53.648494Z",
     "start_time": "2022-04-06T13:20:13.101685Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:23:53.498239Z",
     "iopub.status.busy": "2021-06-13T12:23:53.497763Z",
     "iopub.status.idle": "2021-06-13T12:27:09.346745Z",
     "shell.execute_reply": "2021-06-13T12:27:09.345656Z",
     "shell.execute_reply.started": "2021-06-13T12:23:53.498181Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model_list = [\"resnet50\", \"resnet152\", \"resnext101_32x8d\", \"wide_resnet101_2\", \"densenet\", \"squeezenet\"]\n",
    "model_name = model_list[4] #[4]\n",
    "model_ft, input_size = initialize_model(model_name, num_classes=11)    # input_size = 224\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = model_ft.to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = alpha)\n",
    "scheduler = StepLR(optimizer, step_size = 1, gamma = gam)\n",
    "\n",
    "train_losses = []\n",
    "validation_losses = []\n",
    "for epoch in range(max_epoch):\n",
    "    print(\"======== Epoch: {} ========\".format(epoch + 1))\n",
    "    train(model, device, train_loader, optimizer, epoch, train_losses)\n",
    "    validation(model, device, vali_loader, validation_losses)\n",
    "    \n",
    "plt.plot(train_losses, label='train loss')\n",
    "plt.plot(validation_losses, label='validation loss')\n",
    "plt.legend()\n",
    "plt.title(model_name)\n",
    "plt.show()\n",
    "#print('Best accuracy of '+model_name+' during training: {:.4f}'.format(test_best_acc))\n",
    "\n",
    "torch.save(model.state_dict(), \"trained.model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:52:32.662408Z",
     "start_time": "2022-04-07T13:52:32.656888Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:33:23.976872Z",
     "iopub.status.busy": "2021-06-13T12:33:23.976408Z",
     "iopub.status.idle": "2021-06-13T12:33:23.987331Z",
     "shell.execute_reply": "2021-06-13T12:33:23.985947Z",
     "shell.execute_reply.started": "2021-06-13T12:33:23.976835Z"
    }
   },
   "outputs": [],
   "source": [
    "def predict(model, device, test_loader):\n",
    "    model.eval()\n",
    "    result = []\n",
    "    for (data, path) in test_loader:\n",
    "        path = path[0].split('/')\n",
    "        with torch.no_grad():\n",
    "            data = data.to(device)\n",
    "            y = model(data)\n",
    "            output = nn.Softmax(dim = 1)(y)[0].cpu().numpy()\n",
    "            temp = []\n",
    "            temp.append(path[-1])\n",
    "            for j in range(11):\n",
    "                temp.append(output[j])\n",
    "            result.append(temp)\n",
    "    \n",
    "    df_ = pd.DataFrame(result, columns = ['img', 'c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9', 'c10'])\n",
    "    df_.to_csv(\"result.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-04-07T13:07:37.668210Z",
     "start_time": "2022-04-07T13:07:37.088841Z"
    },
    "execution": {
     "iopub.execute_input": "2021-06-13T12:33:25.560581Z",
     "iopub.status.busy": "2021-06-13T12:33:25.560135Z",
     "iopub.status.idle": "2021-06-13T12:33:25.830638Z",
     "shell.execute_reply": "2021-06-13T12:33:25.829344Z",
     "shell.execute_reply.started": "2021-06-13T12:33:25.560532Z"
    }
   },
   "outputs": [],
   "source": [
    "# model, input_size = initialize_model(\"densenet\", num_classes=10)\n",
    "# model = model_ft.to(device)\n",
    "# model.load_state_dict(torch.load(\"trained.model\"))\n",
    "predict(model, device, test_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "479.844px",
    "left": "605px",
    "right": "20px",
    "top": "119px",
    "width": "335px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
